{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e6549dc-1e68-4d13-aa89-c0de315e91a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n"
     ]
    }
   ],
   "source": [
    "# merge_data.py\n",
    "# merge data_splits and event/time_to_event columns from clinical data\n",
    "import pandas as pd \n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstd,\n",
    "    Orientationd,\n",
    "    Spacingd,\n",
    "    ResampleToMatchd,\n",
    "    CropForegroundd,\n",
    "    ResizeWithPadOrCropd,\n",
    "    NormalizeIntensityd,\n",
    "    ConcatItemsd,\n",
    "    RandAffined,\n",
    "    RandGaussianNoised,\n",
    "    RandBiasFieldd,\n",
    "    RandAdjustContrastd,\n",
    "    NormalizeIntensityd,\n",
    "    MapTransform\n",
    "    \n",
    ")\n",
    "from monai.data import Dataset, DataLoader, ITKReader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Get data splits\n",
    "data_splits = pd.read_csv(\"data_split_5fold.csv\")\n",
    "\n",
    "# Get clinical data\n",
    "clinical_data = pd.read_csv('clinical_data.csv')\n",
    "\n",
    "# Select only relevant columns \"patient_id\", \"BCR\", \"time_to_follow-up/BCR\"\n",
    "df = clinical_data[[\"patient_id\", \"BCR\",\"time_to_follow-up/BCR\"]]\n",
    "\n",
    "# Rename for convenience\n",
    "df = df.rename(columns = {\n",
    "    \"BCR\": \"event\",\n",
    "    \"time_to_follow-up/BCR\": \"time_to_event\"\n",
    "})\n",
    "\n",
    "# Merge data_splits and df\n",
    "df = df.merge(data_splits, on=\"patient_id\")\n",
    "\n",
    "# Split train and test ids\n",
    "train_ids = df[df[\"fold\"] != 0][\"patient_id\"].tolist()\n",
    "test_ids = df[df[\"fold\"] == 0][\"patient_id\"].tolist()\n",
    "\n",
    "# Initialize empty dicts\n",
    "train_files = []\n",
    "test_files = []\n",
    "# create train_dict\n",
    "for patient_id in train_ids:\n",
    "    train_files.append({\n",
    "        \"id\": patient_id,\n",
    "        \"adc\":  f\"radiology/mpMRI/{patient_id}/{patient_id}_0001_adc.mha\",\n",
    "        \"hbv\":  f\"radiology/mpMRI/{patient_id}/{patient_id}_0001_hbv.mha\",\n",
    "        \"t2w\":  f\"radiology/mpMRI/{patient_id}/{patient_id}_0001_t2w.mha\",\n",
    "        \"mask\": f\"radiology/prostate_mask_t2w/{patient_id}_0001_mask.mha\",\n",
    "        \"time_to_event\": df.loc[df[\"patient_id\"] == patient_id, \"time_to_event\"].iloc[0],\n",
    "        \"event\": df.loc[df[\"patient_id\"] == patient_id, \"event\"].iloc[0]\n",
    "                            \n",
    "    })\n",
    "    \n",
    "# create train_dict\n",
    "for patient_id in test_ids:\n",
    "    test_files.append({\n",
    "        \"id\": patient_id,\n",
    "        \"adc\":  f\"radiology/mpMRI/{patient_id}/{patient_id}_0001_adc.mha\",\n",
    "        \"hbv\":  f\"radiology/mpMRI/{patient_id}/{patient_id}_0001_hbv.mha\",\n",
    "        \"t2w\":  f\"radiology/mpMRI/{patient_id}/{patient_id}_0001_t2w.mha\",\n",
    "        \"mask\": f\"radiology/prostate_mask_t2w/{patient_id}_0001_mask.mha\",\n",
    "        \"time_to_event\": df.loc[df[\"patient_id\"] == patient_id, \"time_to_event\"].iloc[0],\n",
    "        \"event\": df.loc[df[\"patient_id\"] == patient_id, \"event\"].iloc[0]\n",
    "                            \n",
    "    })\n",
    "\n",
    "target_spacing = (1.0, 1.0, 3.0)\n",
    "target_shape   = (160, 160, 48)   # pick something reasonable\n",
    "\n",
    "keys_img = [\"adc\", \"hbv\", \"t2w\"]\n",
    "keys_all = [\"adc\", \"hbv\", \"t2w\", \"mask\"]\n",
    "    \n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=keys_all, \n",
    "               reader=ITKReader(), \n",
    "               image_only=False),\n",
    "    EnsureChannelFirstd(keys=keys_all),\n",
    "    Orientationd(keys=keys_all, axcodes=\"RAS\"),\n",
    "    Spacingd(\n",
    "        keys=[\"t2w\"],\n",
    "        pixdim=target_spacing,\n",
    "        mode=(\"trilinear\",),\n",
    "    ),\n",
    "    Spacingd(\n",
    "        keys=[\"mask\"],\n",
    "        pixdim=target_spacing,\n",
    "        mode=(\"nearest\",),\n",
    "    ),\n",
    "    ResampleToMatchd(\n",
    "        keys=[\"adc\", \"hbv\"],\n",
    "        key_dst=\"t2w\",                \n",
    "        mode=(\"trilinear\", \"trilinear\"),\n",
    "    ),\n",
    "    CropForegroundd(\n",
    "        keys=keys_all,\n",
    "        source_key=\"mask\",\n",
    "        margin=(16, 16, 2),\n",
    "    ),\n",
    "    ResizeWithPadOrCropd(\n",
    "        keys=keys_all,\n",
    "        spatial_size=target_shape,\n",
    "    ),\n",
    "    RandAffined(\n",
    "        keys=keys_img,\n",
    "        spatial_size=target_shape,     \n",
    "        rotate_range=(0.087, 0.087, 0.087),\n",
    "        translate_range=(5, 5, 1),\n",
    "        scale_range=(0.05, 0.05, 0.0),\n",
    "        mode=(\"trilinear\",) * len(keys_img),\n",
    "        prob=0.5,\n",
    "    ),\n",
    "    RandGaussianNoised(keys=keys_img, prob=0.2, mean=0, std=0.01),\n",
    "    RandBiasFieldd(keys=keys_img, prob=0.3, coeff_range=(0.0, 0.1)),\n",
    "    RandAdjustContrastd(keys=keys_img, prob=0.3, gamma=(0.9, 1.1)),\n",
    "    NormalizeIntensityd(\n",
    "        keys=keys_img,\n",
    "        nonzero=True,\n",
    "        channel_wise=True,\n",
    "    ),\n",
    "    ConcatItemsd(\n",
    "        keys=[\"adc\", \"hbv\", \"t2w\"],\n",
    "        name=\"image\",\n",
    "        dim=0,\n",
    "    ),\n",
    "])\n",
    "\n",
    "test_transforms = Compose([\n",
    "    LoadImaged(keys=keys_all, \n",
    "               reader=ITKReader(), \n",
    "               image_only=False),\n",
    "    EnsureChannelFirstd(keys=keys_all),\n",
    "    Orientationd(keys=keys_all, axcodes=\"RAS\"),\n",
    "    Spacingd(\n",
    "        keys=[\"t2w\"],\n",
    "        pixdim=target_spacing,\n",
    "        mode=(\"trilinear\",),\n",
    "    ),\n",
    "    Spacingd(\n",
    "        keys=[\"mask\"],\n",
    "        pixdim=target_spacing,\n",
    "        mode=(\"nearest\",),\n",
    "    ),\n",
    "    ResampleToMatchd(\n",
    "        keys=[\"adc\", \"hbv\"],\n",
    "        key_dst=\"t2w\",                \n",
    "        mode=(\"trilinear\", \"trilinear\"),\n",
    "    ),\n",
    "    CropForegroundd(\n",
    "        keys=keys_all,\n",
    "        source_key=\"mask\",\n",
    "        margin=(16, 16, 2),\n",
    "    ),\n",
    "    ResizeWithPadOrCropd(\n",
    "        keys=keys_all,\n",
    "        spatial_size=target_shape,\n",
    "    ),\n",
    "    NormalizeIntensityd(\n",
    "        keys=keys_img,\n",
    "        nonzero=True,\n",
    "        channel_wise=True,\n",
    "    ),\n",
    "    ConcatItemsd(\n",
    "        keys=[\"adc\", \"hbv\", \"t2w\"],\n",
    "        name=\"image\",\n",
    "        dim=0,\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_ds = Dataset(train_files, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "for batch in train_loader:\n",
    "    images = batch[\"image\"]\n",
    "    times  = batch[\"time_to_event\"]\n",
    "    events = batch[\"event\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b6468c6-0fad-4456-9064-9f45c99109d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import DenseNet121\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ðŸ‘‰ CHANGE THIS to how many channels you actually stacked:\n",
    "# adc + hbv + t2w  â†’ in_channels = 3\n",
    "# just t2w         â†’ in_channels = 1\n",
    "in_channels = 3  \n",
    "\n",
    "model = DenseNet121(\n",
    "    spatial_dims=3,      # 3D volumes\n",
    "    in_channels=in_channels,\n",
    "    out_channels=1,      # single risk score per patient\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b65de7-5da8-46c8-a93c-0f5e80d36173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Suppose your preprocessed images are (B, C, D, H, W)\n",
    "x = torch.randn(2, in_channels, 64, 128, 128).to(device)  # fake batch\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "print(out.shape)   # should be torch.Size([2, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m31",
   "language": "python",
   "name": "m31"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
